{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca77e8d-7d39-4d25-b030-8af8069a4f6b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c3cb63f-e069-444e-8993-c5dee3e4aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afaef68-373b-4d04-9f99-c5367c04dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Onur Ege\\AppData\\Local\\Temp\\ipykernel_2612\\17096404.py:7: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  basics = pd.read_csv(os.path.join(IMDB_DATA_PATH, \"title.basics.tsv\"), sep='\\t', na_values='\\\\N')\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "IMDB_DATA_PATH = \"PATH\"\n",
    "OUTPUT_PATH = \"PATH\"\n",
    "\n",
    "# 1. Load IMDb Datasets\n",
    "print(\"Loading datasets...\")\n",
    "basics = pd.read_csv(os.path.join(IMDB_DATA_PATH, \"title.basics.tsv\"), sep='\\t', na_values='\\\\N')\n",
    "crew = pd.read_csv(os.path.join(IMDB_DATA_PATH, \"title.crew.tsv\"), sep='\\t', na_values='\\\\N')\n",
    "principals = pd.read_csv(os.path.join(IMDB_DATA_PATH, \"title.principals.tsv\"), sep='\\t', na_values='\\\\N')\n",
    "names = pd.read_csv(os.path.join(IMDB_DATA_PATH, \"name.basics.tsv\"), sep='\\t', na_values='\\\\N')\n",
    "ratings = pd.read_csv(os.path.join(IMDB_DATA_PATH, \"title.ratings.tsv\"), sep='\\t', na_values='\\\\N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688ebb0-b1d6-40e5-bfb9-a6139a4ddd62",
   "metadata": {},
   "source": [
    "### movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073ac2a9-7fa4-44a5-96f6-9c45ab0816d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering clean movies...\n",
      "Number of cleaned movies: 316159\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter only Movies (excluding Episodes)\n",
    "print(\"Filtering clean movies...\")\n",
    "\n",
    "# Keep only movies\n",
    "movies = basics[basics['titleType'] == 'movie']\n",
    "\n",
    "# Drop movies with titles that indicate episodes\n",
    "episode_indicators = ['Episode', 'episode', '#', 'Part', 'part']\n",
    "\n",
    "def is_episode(title):\n",
    "    return any(indicator in str(title) for indicator in episode_indicators)\n",
    "\n",
    "movies = movies[~movies['primaryTitle'].apply(is_episode)]\n",
    "\n",
    "# Drop NA values\n",
    "movies = movies[['tconst', 'primaryTitle', 'startYear', 'genres']].dropna()\n",
    "\n",
    "# Merge ratings\n",
    "movies = movies.merge(ratings, on='tconst', how='left')\n",
    "movies = movies.dropna(subset=['averageRating', 'numVotes'])\n",
    "\n",
    "print(f\"Number of cleaned movies: {len(movies)}\")\n",
    "\n",
    "# Save Movie nodes\n",
    "movies_out = movies.rename(columns={\n",
    "    'tconst': 'id',\n",
    "    'primaryTitle': 'title',\n",
    "    'startYear': 'year',\n",
    "    'averageRating': 'rating',\n",
    "    'numVotes': 'votes'\n",
    "})\n",
    "movies_out['year'] = movies_out['year'].astype(int)\n",
    "movies_out.to_csv(os.path.join(OUTPUT_PATH, \"movies.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cd9ba7-f897-4382-9ac7-b4884d0a3abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>startYear</th>\n",
       "      <th>genres</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534162</th>\n",
       "      <td>tt9916362</td>\n",
       "      <td>Coven</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Drama,History</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534163</th>\n",
       "      <td>tt9916428</td>\n",
       "      <td>The Secret of China</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Adventure,History,War</td>\n",
       "      <td>4.7</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534164</th>\n",
       "      <td>tt9916538</td>\n",
       "      <td>Kuambil Lagi Hatiku</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534167</th>\n",
       "      <td>tt9916706</td>\n",
       "      <td>Dankyavar Danka</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534168</th>\n",
       "      <td>tt9916730</td>\n",
       "      <td>6 Gunn</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst         primaryTitle  startYear                 genres  \\\n",
       "534162  tt9916362                Coven     2020.0          Drama,History   \n",
       "534163  tt9916428  The Secret of China     2019.0  Adventure,History,War   \n",
       "534164  tt9916538  Kuambil Lagi Hatiku     2019.0                  Drama   \n",
       "534167  tt9916706      Dankyavar Danka     2013.0                 Comedy   \n",
       "534168  tt9916730               6 Gunn     2017.0                  Drama   \n",
       "\n",
       "        averageRating  numVotes  \n",
       "534162            6.4    6035.0  \n",
       "534163            4.7      22.0  \n",
       "534164            8.3      10.0  \n",
       "534167            7.7       9.0  \n",
       "534168            7.0      13.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befafe7-6cac-4483-930f-24cf3794871b",
   "metadata": {},
   "source": [
    "### genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbfaf1d2-5f93-45b5-b791-3510b0a4bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting genres...\n"
     ]
    }
   ],
   "source": [
    "# 3. Extract Genres separately\n",
    "print(\"Extracting genres...\")\n",
    "all_genres = set()\n",
    "movies_out['genres'].str.split(',').apply(all_genres.update)\n",
    "genres_out = pd.DataFrame({'name': list(all_genres)})\n",
    "genres_out.to_csv(os.path.join(OUTPUT_PATH, \"genres.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941c71a6-86f4-45e3-84e4-653747148168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name\n",
       "0  Adventure\n",
       "1      Sport\n",
       "2  Animation\n",
       "3      Drama\n",
       "4     Action"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785236a-7ca5-4dc8-8953-03956862aadf",
   "metadata": {},
   "source": [
    "### people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "508630ef-c8c4-46de-a4e8-7e4df35269eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering actors and directors...\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter People (Actors, Directors)\n",
    "print(\"Filtering actors and directors...\")\n",
    "principals = principals[principals['category'].isin(['actor', 'actress', 'director'])]\n",
    "\n",
    "# Only keep top 8 actors/actresses per movie + directors\n",
    "actors = principals[(principals['category'].isin(['actor', 'actress'])) & (principals['ordering'] <= 8)]\n",
    "directors = principals[principals['category'] == 'director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "015a21bf-fafe-4579-a41d-d3a67a2f65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = actors[['nconst', 'tconst']]\n",
    "actors.columns = ['personId', 'movieId']\n",
    "actors.to_csv(os.path.join(OUTPUT_PATH, \"actors.csv\"), index=False)\n",
    "\n",
    "directors = directors[['nconst', 'tconst']]\n",
    "directors.columns = ['personId', 'movieId']\n",
    "directors.to_csv(os.path.join(OUTPUT_PATH, \"directors.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c3ca9c6-ad12-4dfb-9017-ecd5c77f6fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nm0443482</td>\n",
       "      <td>tt0000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nm0653042</td>\n",
       "      <td>tt0000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nm0179163</td>\n",
       "      <td>tt0000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nm0183947</td>\n",
       "      <td>tt0000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nm0653028</td>\n",
       "      <td>tt0000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     personId    movieId\n",
       "14  nm0443482  tt0000005\n",
       "15  nm0653042  tt0000005\n",
       "17  nm0179163  tt0000007\n",
       "18  nm0183947  tt0000007\n",
       "24  nm0653028  tt0000008"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb82eeb-cb9c-44b5-879c-770c2fdc53c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0005690</td>\n",
       "      <td>tt0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0721526</td>\n",
       "      <td>tt0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nm0721526</td>\n",
       "      <td>tt0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nm0721526</td>\n",
       "      <td>tt0000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nm0005690</td>\n",
       "      <td>tt0000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     personId    movieId\n",
       "1   nm0005690  tt0000001\n",
       "4   nm0721526  tt0000002\n",
       "6   nm0721526  tt0000003\n",
       "12  nm0721526  tt0000004\n",
       "19  nm0005690  tt0000007"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd54c16a-650d-48af-a7b2-fed51eee546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing people nodes...\n"
     ]
    }
   ],
   "source": [
    "# 5. Prepare People Nodes\n",
    "print(\"Preparing people nodes...\")\n",
    "people_ids = set(actors['personId']).union(directors['personId'])\n",
    "people = names[names['nconst'].isin(people_ids)][['nconst', 'primaryName', 'birthYear', 'primaryProfession']]\n",
    "people = people.rename(columns={\n",
    "    'nconst': 'id',\n",
    "    'primaryName': 'name'\n",
    "})\n",
    "people.to_csv(os.path.join(OUTPUT_PATH, \"people.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c173cea3-28b2-4adf-b55e-4d071b11ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>actor,miscellaneous,producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>actress,soundtrack,archive_footage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>actress,music_department,producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>actor,writer,music_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>writer,director,actor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             name  birthYear                   primaryProfession\n",
       "0  nm0000001     Fred Astaire     1899.0        actor,miscellaneous,producer\n",
       "1  nm0000002    Lauren Bacall     1924.0  actress,soundtrack,archive_footage\n",
       "2  nm0000003  Brigitte Bardot     1934.0   actress,music_department,producer\n",
       "3  nm0000004     John Belushi     1949.0       actor,writer,music_department\n",
       "4  nm0000005   Ingmar Bergman     1918.0               writer,director,actor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fe70b-7df5-41ba-ad2b-81e715ca5049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29d569aa-e03f-465f-baef-cf8fe597f2ff",
   "metadata": {},
   "source": [
    "# Import to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf5c34b-ee52-42ea-bb9d-3f15c730ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd207156-21de-4c6e-9a5b-20548952b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j database\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"PASSWORD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "943c7746-f456-4463-bb5b-731796cd8025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE CONSTRAİNTS\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (m:Movie) REQUIRE m.id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (p:Person) REQUIRE p.id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (g:Genre) REQUIRE g.name IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (u:User) REQUIRE u.id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (u:Actor) REQUIRE u.id IS UNIQUE;\")\n",
    "graph.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (u:Director) REQUIRE u.id IS UNIQUE;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb1d485-31eb-4e28-8a35-3da3237f1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV \n",
    "movies_df = pd.read_csv(\"C:/Users/Onur Ege/PycharmProjects/GraphDBProject/dataset/processed/movies.csv\")\n",
    "genres_df = pd.read_csv(\"C:/Users/Onur Ege/PycharmProjects/GraphDBProject/dataset/processed/genres.csv\")\n",
    "people_df = pd.read_csv(\"C:/Users/Onur Ege/PycharmProjects/GraphDBProject/dataset/processed/people.csv\")\n",
    "actors_df = pd.read_csv(\"C:/Users/Onur Ege/PycharmProjects/GraphDBProject/dataset/processed/actors.csv\")\n",
    "directors_df = pd.read_csv(\"C:/Users/Onur Ege/PycharmProjects/GraphDBProject/dataset/processed/directors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50202659-53a5-486a-8026-809a19cfc0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316159, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7017fbe-12db-46fe-b9ab-cf810b5e08be",
   "metadata": {},
   "source": [
    "### insert movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee841f-6706-4434-8a9c-91dc5ee9da8b",
   "metadata": {},
   "source": [
    "##### some movies dont have any actor(short movie,audio book), delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ed09e3-e2ad-4ff4-b729-7dd054391197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for inserting movies\n",
    "batch_size = 500  # size\n",
    "\n",
    "def insert_movies_part(movies_df_part, graph, part_name=\"Part\"):\n",
    "    tx = graph.begin()\n",
    "    \n",
    "    for index, row in movies_df_part.iterrows():\n",
    "        # Safely parse genres\n",
    "        genres = []\n",
    "        if pd.notna(row.get('genres')):\n",
    "            if isinstance(row['genres'], str):\n",
    "                try:\n",
    "                    genres = eval(row['genres'])  # if genres stored like '[\"Action\", \"Comedy\"]'\n",
    "                except:\n",
    "                    genres = row['genres'].split('|')  # if genres stored like \"Action|Comedy\"\n",
    "            else:\n",
    "                genres = row['genres']\n",
    "\n",
    "        movie = Node(\"Movie\",\n",
    "                     id=row['id'],\n",
    "                     title=row['title'],\n",
    "                     year=int(row['year']) if not pd.isna(row['year']) else None,\n",
    "                     rating=float(row['rating']) if not pd.isna(row['rating']) else None,\n",
    "                     votes=int(row['votes']) if not pd.isna(row['votes']) else None,\n",
    "                     genres=genres)\n",
    "\n",
    "        tx.merge(movie, \"Movie\", \"id\")\n",
    "        \n",
    "        if index % batch_size == 0 and index != 0:\n",
    "            tx.commit()\n",
    "            print(f\"✅ {part_name} - Committed at index {index}\")\n",
    "            tx = graph.begin()\n",
    "\n",
    "    tx.commit()\n",
    "    print(f\"✅✅ {part_name} Finished inserting movies with genres!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948f3d07-5815-4c76-bd00-0fd6923fa018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "#insert_movies_part(movies_df.iloc[0:50000], graph, part_name=\"Part 1\")\n",
    "\n",
    "# Part 2\n",
    "#insert_movies_part(movies_df.iloc[50000:100000], graph, part_name=\"Part 2\")\n",
    "\n",
    "# Part 3\n",
    "#insert_movies_part(movies_df.iloc[100000:150000], graph, part_name=\"Part 3\")\n",
    "\n",
    "# Part 4\n",
    "#insert_movies_part(movies_df.iloc[150000:200000], graph, part_name=\"Part 4\")\n",
    "\n",
    "# Part 5\n",
    "#insert_movies_part(movies_df.iloc[200000:250000], graph, part_name=\"Part 5\")\n",
    "\n",
    "# Part 6\n",
    "#insert_movies_part(movies_df.iloc[250000:300000], graph, part_name=\"Part 6\")\n",
    "\n",
    "# Part 7\n",
    "#insert_movies_part(movies_df.iloc[300000:], graph, part_name=\"Part 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e48c8-9470-4eca-b794-1fa62e87b3fb",
   "metadata": {},
   "source": [
    "### insert genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fc6209-f09b-4ea2-8026-0d581947d346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅✅ All genres inserted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Onur Ege\\AppData\\Local\\Temp\\ipykernel_22928\\3844082110.py:12: DeprecationWarning: The transaction.commit() method is deprecated, use graph.commit(transaction) instead\n",
      "  tx.commit()\n"
     ]
    }
   ],
   "source": [
    "tx = graph.begin()\n",
    "\n",
    "for index, row in genres_df.iterrows():\n",
    "    genre = Node(\"Genre\", name=row['name'])\n",
    "    tx.merge(genre, \"Genre\", \"name\")\n",
    "    \n",
    "    if index % 500 == 0 and index != 0:\n",
    "        tx.commit()\n",
    "        print(f\"✅ Inserted {index} genres\")\n",
    "        tx = graph.begin()\n",
    "\n",
    "tx.commit()\n",
    "print(\"✅✅ All genres inserted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66e8b7-ff36-4309-be93-d5cd99f7fdc7",
   "metadata": {},
   "source": [
    "### Insert Person Nodes (Actors and Directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2fa4f05-5a97-4377-96bd-4678da09db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_person_part(people_df,graph,part_name=\"Part\"):\n",
    "    tx = graph.begin()\n",
    "    \n",
    "    for index, row in people_df.iterrows():\n",
    "        professions = str(row['primaryProfession']).split(',')\n",
    "        person = Node(\"Person\",\n",
    "                      id=row['id'],\n",
    "                      name=row['name'],\n",
    "                      birthYear=int(row['birthYear']) if not pd.isna(row['birthYear']) else None,\n",
    "                      primaryProfession=professions)\n",
    "        tx.merge(person, \"Person\", \"id\")\n",
    "        \n",
    "        if 'actor' in professions or 'actress' in professions:\n",
    "            person.add_label(\"Actor\")\n",
    "        if 'director' in professions:\n",
    "            person.add_label(\"Director\")\n",
    "            \n",
    "        graph.push(person)\n",
    "\n",
    "        if index % 500 == 0 and index != 0:\n",
    "            tx.commit()\n",
    "            print(f\"✅ Inserted {index} people\")\n",
    "            tx = graph.begin()\n",
    "    \n",
    "    tx.commit()\n",
    "    print(\"✅✅ All people inserted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8905d3a3-568d-4814-baf7-0dfaf995cbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3675633, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a308d1d0-d78c-435b-9b24-321bc50e162e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3675628</th>\n",
       "      <td>nm9993700</td>\n",
       "      <td>Sexy Angel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675629</th>\n",
       "      <td>nm9993701</td>\n",
       "      <td>Sanjai Kuriakose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675630</th>\n",
       "      <td>nm9993703</td>\n",
       "      <td>James Craigmyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675631</th>\n",
       "      <td>nm9993708</td>\n",
       "      <td>Eli Bevins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,director,writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675632</th>\n",
       "      <td>nm9993709</td>\n",
       "      <td>Lu Bevins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,writer,director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id              name  birthYear         primaryProfession\n",
       "3675628  nm9993700        Sexy Angel        NaN                   actress\n",
       "3675629  nm9993701  Sanjai Kuriakose        NaN                     actor\n",
       "3675630  nm9993703   James Craigmyle        NaN                     actor\n",
       "3675631  nm9993708        Eli Bevins        NaN  producer,director,writer\n",
       "3675632  nm9993709         Lu Bevins        NaN  producer,writer,director"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e335ed64-1d2b-452f-a818-45352fe6c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,37):\n",
    "   # insert_person_part(people_df.iloc[(i-1)*100000:i*100000], graph, part_name='Part ' + str(i))\n",
    "#insert_person_part(people_df.iloc[3500000:], graph, part_name='Part 37')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df47e29-bfa3-4e85-91e8-c968621ff87c",
   "metadata": {},
   "source": [
    "### create IN_GENRE relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f4e8cb9-8eff-4543-82cf-83b632fec30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 IN_GENRE relationships creation completed successfully with APOC!\n"
     ]
    }
   ],
   "source": [
    "# 3. Define APOC query for IN_GENRE relationships\n",
    "in_genre_query = \"\"\"\n",
    "CALL apoc.periodic.iterate(\n",
    "  \"\n",
    "  MATCH (m:Movie)\n",
    "  WHERE NOT (m)-[:IN_GENRE]->(:Genre) AND m.genres IS NOT NULL\n",
    "  RETURN m\n",
    "  \",\n",
    "  \"\n",
    "  UNWIND m.genres AS genreName\n",
    "  MATCH (g:Genre {name: genreName})\n",
    "  MERGE (m)-[:IN_GENRE]->(g)\n",
    "  \",\n",
    "  {batchSize:500, parallel:false}\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 4. Run the APOC batch query\n",
    "graph.run(in_genre_query)\n",
    "\n",
    "print(\"🎯 IN_GENRE relationships creation completed successfully with APOC!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf95019-ad7b-4dda-9dde-dbc254f37a04",
   "metadata": {},
   "source": [
    "### create ACTED_IN relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8820173e-7797-41aa-945a-00c4ba563130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32892665, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af6f9f5-5791-410f-8d0f-feea4d6169ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare rows\n",
    "acted_in_row = actors_df[['personId', 'movieId']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65832c9e-5904-4d12-8588-6d02305d1df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32892665"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acted_in_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3602dff8-7c03-4e14-902c-60c5827a8cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Total chunks to send: 1097\n",
      "🚀 Sending chunk 1/1097 (rows 30000)\n",
      "✅ Chunk 1 finished.\n",
      "🚀 Sending chunk 2/1097 (rows 30000)\n",
      "✅ Chunk 2 finished.\n",
      "🚀 Sending chunk 3/1097 (rows 30000)\n",
      "✅ Chunk 3 finished.\n",
      "🚀 Sending chunk 4/1097 (rows 30000)\n",
      "✅ Chunk 4 finished.\n",
      "🚀 Sending chunk 5/1097 (rows 30000)\n",
      "✅ Chunk 5 finished.\n",
      "🚀 Sending chunk 6/1097 (rows 30000)\n",
      "✅ Chunk 6 finished.\n",
      "🚀 Sending chunk 7/1097 (rows 30000)\n",
      "✅ Chunk 7 finished.\n",
      "🚀 Sending chunk 8/1097 (rows 30000)\n",
      "✅ Chunk 8 finished.\n",
      "🚀 Sending chunk 9/1097 (rows 30000)\n",
      "✅ Chunk 9 finished.\n",
      "🚀 Sending chunk 10/1097 (rows 30000)\n",
      "✅ Chunk 10 finished.\n",
      "🚀 Sending chunk 11/1097 (rows 30000)\n",
      "✅ Chunk 11 finished.\n",
      "🚀 Sending chunk 12/1097 (rows 30000)\n",
      "✅ Chunk 12 finished.\n",
      "🚀 Sending chunk 13/1097 (rows 30000)\n",
      "✅ Chunk 13 finished.\n",
      "🚀 Sending chunk 14/1097 (rows 30000)\n",
      "✅ Chunk 14 finished.\n",
      "🚀 Sending chunk 15/1097 (rows 30000)\n",
      "✅ Chunk 15 finished.\n",
      "🚀 Sending chunk 16/1097 (rows 30000)\n",
      "✅ Chunk 16 finished.\n",
      "🚀 Sending chunk 17/1097 (rows 30000)\n",
      "✅ Chunk 17 finished.\n",
      "🚀 Sending chunk 18/1097 (rows 30000)\n",
      "✅ Chunk 18 finished.\n",
      "🚀 Sending chunk 19/1097 (rows 30000)\n",
      "✅ Chunk 19 finished.\n",
      "🚀 Sending chunk 20/1097 (rows 30000)\n",
      "✅ Chunk 20 finished.\n",
      "🚀 Sending chunk 21/1097 (rows 30000)\n",
      "✅ Chunk 21 finished.\n",
      "🚀 Sending chunk 22/1097 (rows 30000)\n",
      "✅ Chunk 22 finished.\n",
      "🚀 Sending chunk 23/1097 (rows 30000)\n",
      "✅ Chunk 23 finished.\n",
      "🚀 Sending chunk 24/1097 (rows 30000)\n",
      "✅ Chunk 24 finished.\n",
      "🚀 Sending chunk 25/1097 (rows 30000)\n",
      "✅ Chunk 25 finished.\n",
      "🚀 Sending chunk 26/1097 (rows 30000)\n",
      "✅ Chunk 26 finished.\n",
      "🚀 Sending chunk 27/1097 (rows 30000)\n",
      "✅ Chunk 27 finished.\n",
      "🚀 Sending chunk 28/1097 (rows 30000)\n",
      "✅ Chunk 28 finished.\n",
      "🚀 Sending chunk 29/1097 (rows 30000)\n",
      "✅ Chunk 29 finished.\n",
      "🚀 Sending chunk 30/1097 (rows 30000)\n",
      "✅ Chunk 30 finished.\n",
      "🚀 Sending chunk 31/1097 (rows 30000)\n",
      "✅ Chunk 31 finished.\n",
      "🚀 Sending chunk 32/1097 (rows 30000)\n",
      "✅ Chunk 32 finished.\n",
      "🚀 Sending chunk 33/1097 (rows 30000)\n",
      "✅ Chunk 33 finished.\n",
      "🚀 Sending chunk 34/1097 (rows 30000)\n",
      "✅ Chunk 34 finished.\n",
      "🚀 Sending chunk 35/1097 (rows 30000)\n",
      "✅ Chunk 35 finished.\n",
      "🚀 Sending chunk 36/1097 (rows 30000)\n",
      "✅ Chunk 36 finished.\n",
      "🚀 Sending chunk 37/1097 (rows 30000)\n",
      "✅ Chunk 37 finished.\n",
      "🚀 Sending chunk 38/1097 (rows 30000)\n",
      "✅ Chunk 38 finished.\n",
      "🚀 Sending chunk 39/1097 (rows 30000)\n",
      "✅ Chunk 39 finished.\n",
      "🚀 Sending chunk 40/1097 (rows 30000)\n",
      "✅ Chunk 40 finished.\n",
      "🚀 Sending chunk 41/1097 (rows 30000)\n",
      "✅ Chunk 41 finished.\n",
      "🚀 Sending chunk 42/1097 (rows 30000)\n",
      "✅ Chunk 42 finished.\n",
      "🚀 Sending chunk 43/1097 (rows 30000)\n",
      "✅ Chunk 43 finished.\n",
      "🚀 Sending chunk 44/1097 (rows 30000)\n",
      "✅ Chunk 44 finished.\n",
      "🚀 Sending chunk 45/1097 (rows 30000)\n",
      "✅ Chunk 45 finished.\n",
      "🚀 Sending chunk 46/1097 (rows 30000)\n",
      "✅ Chunk 46 finished.\n",
      "🚀 Sending chunk 47/1097 (rows 30000)\n",
      "✅ Chunk 47 finished.\n",
      "🚀 Sending chunk 48/1097 (rows 30000)\n",
      "✅ Chunk 48 finished.\n",
      "🚀 Sending chunk 49/1097 (rows 30000)\n",
      "✅ Chunk 49 finished.\n",
      "🚀 Sending chunk 50/1097 (rows 30000)\n",
      "✅ Chunk 50 finished.\n",
      "🚀 Sending chunk 51/1097 (rows 30000)\n",
      "✅ Chunk 51 finished.\n",
      "🚀 Sending chunk 52/1097 (rows 30000)\n",
      "✅ Chunk 52 finished.\n",
      "🚀 Sending chunk 53/1097 (rows 30000)\n",
      "✅ Chunk 53 finished.\n",
      "🚀 Sending chunk 54/1097 (rows 30000)\n",
      "✅ Chunk 54 finished.\n",
      "🚀 Sending chunk 55/1097 (rows 30000)\n",
      "✅ Chunk 55 finished.\n",
      "🚀 Sending chunk 56/1097 (rows 30000)\n",
      "✅ Chunk 56 finished.\n",
      "🚀 Sending chunk 57/1097 (rows 30000)\n",
      "✅ Chunk 57 finished.\n",
      "🚀 Sending chunk 58/1097 (rows 30000)\n",
      "✅ Chunk 58 finished.\n",
      "🚀 Sending chunk 59/1097 (rows 30000)\n",
      "✅ Chunk 59 finished.\n",
      "🚀 Sending chunk 60/1097 (rows 30000)\n",
      "✅ Chunk 60 finished.\n",
      "🚀 Sending chunk 61/1097 (rows 30000)\n",
      "✅ Chunk 61 finished.\n",
      "🚀 Sending chunk 62/1097 (rows 30000)\n",
      "✅ Chunk 62 finished.\n",
      "🚀 Sending chunk 63/1097 (rows 30000)\n",
      "✅ Chunk 63 finished.\n",
      "🚀 Sending chunk 64/1097 (rows 30000)\n",
      "✅ Chunk 64 finished.\n",
      "🚀 Sending chunk 65/1097 (rows 30000)\n",
      "✅ Chunk 65 finished.\n",
      "🚀 Sending chunk 66/1097 (rows 30000)\n",
      "✅ Chunk 66 finished.\n",
      "🚀 Sending chunk 67/1097 (rows 30000)\n",
      "✅ Chunk 67 finished.\n",
      "🚀 Sending chunk 68/1097 (rows 30000)\n",
      "✅ Chunk 68 finished.\n",
      "🚀 Sending chunk 69/1097 (rows 30000)\n",
      "✅ Chunk 69 finished.\n",
      "🚀 Sending chunk 70/1097 (rows 30000)\n",
      "✅ Chunk 70 finished.\n",
      "🚀 Sending chunk 71/1097 (rows 30000)\n",
      "✅ Chunk 71 finished.\n",
      "🚀 Sending chunk 72/1097 (rows 30000)\n",
      "✅ Chunk 72 finished.\n",
      "🚀 Sending chunk 73/1097 (rows 30000)\n",
      "✅ Chunk 73 finished.\n",
      "🚀 Sending chunk 74/1097 (rows 30000)\n",
      "✅ Chunk 74 finished.\n",
      "🚀 Sending chunk 75/1097 (rows 30000)\n",
      "✅ Chunk 75 finished.\n",
      "🚀 Sending chunk 76/1097 (rows 30000)\n",
      "✅ Chunk 76 finished.\n",
      "🚀 Sending chunk 77/1097 (rows 30000)\n",
      "✅ Chunk 77 finished.\n",
      "🚀 Sending chunk 78/1097 (rows 30000)\n",
      "✅ Chunk 78 finished.\n",
      "🚀 Sending chunk 79/1097 (rows 30000)\n",
      "✅ Chunk 79 finished.\n",
      "🚀 Sending chunk 80/1097 (rows 30000)\n",
      "✅ Chunk 80 finished.\n",
      "🚀 Sending chunk 81/1097 (rows 30000)\n",
      "✅ Chunk 81 finished.\n",
      "🚀 Sending chunk 82/1097 (rows 30000)\n",
      "✅ Chunk 82 finished.\n",
      "🚀 Sending chunk 83/1097 (rows 30000)\n",
      "✅ Chunk 83 finished.\n",
      "🚀 Sending chunk 84/1097 (rows 30000)\n",
      "✅ Chunk 84 finished.\n",
      "🚀 Sending chunk 85/1097 (rows 30000)\n",
      "✅ Chunk 85 finished.\n",
      "🚀 Sending chunk 86/1097 (rows 30000)\n",
      "✅ Chunk 86 finished.\n",
      "🚀 Sending chunk 87/1097 (rows 30000)\n",
      "✅ Chunk 87 finished.\n",
      "🚀 Sending chunk 88/1097 (rows 30000)\n",
      "✅ Chunk 88 finished.\n",
      "🚀 Sending chunk 89/1097 (rows 30000)\n",
      "✅ Chunk 89 finished.\n",
      "🚀 Sending chunk 90/1097 (rows 30000)\n",
      "✅ Chunk 90 finished.\n",
      "🚀 Sending chunk 91/1097 (rows 30000)\n",
      "✅ Chunk 91 finished.\n",
      "🚀 Sending chunk 92/1097 (rows 30000)\n",
      "✅ Chunk 92 finished.\n",
      "🚀 Sending chunk 93/1097 (rows 30000)\n",
      "✅ Chunk 93 finished.\n",
      "🚀 Sending chunk 94/1097 (rows 30000)\n",
      "✅ Chunk 94 finished.\n",
      "🚀 Sending chunk 95/1097 (rows 30000)\n",
      "✅ Chunk 95 finished.\n",
      "🚀 Sending chunk 96/1097 (rows 30000)\n",
      "✅ Chunk 96 finished.\n",
      "🚀 Sending chunk 97/1097 (rows 30000)\n",
      "✅ Chunk 97 finished.\n",
      "🚀 Sending chunk 98/1097 (rows 30000)\n",
      "✅ Chunk 98 finished.\n",
      "🚀 Sending chunk 99/1097 (rows 30000)\n",
      "✅ Chunk 99 finished.\n",
      "🚀 Sending chunk 100/1097 (rows 30000)\n",
      "✅ Chunk 100 finished.\n",
      "🚀 Sending chunk 101/1097 (rows 30000)\n",
      "✅ Chunk 101 finished.\n",
      "🚀 Sending chunk 102/1097 (rows 30000)\n",
      "✅ Chunk 102 finished.\n",
      "🚀 Sending chunk 103/1097 (rows 30000)\n",
      "✅ Chunk 103 finished.\n",
      "🚀 Sending chunk 104/1097 (rows 30000)\n",
      "✅ Chunk 104 finished.\n",
      "🚀 Sending chunk 105/1097 (rows 30000)\n",
      "✅ Chunk 105 finished.\n",
      "🚀 Sending chunk 106/1097 (rows 30000)\n",
      "✅ Chunk 106 finished.\n",
      "🚀 Sending chunk 107/1097 (rows 30000)\n",
      "✅ Chunk 107 finished.\n",
      "🚀 Sending chunk 108/1097 (rows 30000)\n",
      "✅ Chunk 108 finished.\n",
      "🚀 Sending chunk 109/1097 (rows 30000)\n",
      "✅ Chunk 109 finished.\n",
      "🚀 Sending chunk 110/1097 (rows 30000)\n",
      "✅ Chunk 110 finished.\n",
      "🚀 Sending chunk 111/1097 (rows 30000)\n",
      "✅ Chunk 111 finished.\n",
      "🚀 Sending chunk 112/1097 (rows 30000)\n",
      "✅ Chunk 112 finished.\n",
      "🚀 Sending chunk 113/1097 (rows 30000)\n",
      "✅ Chunk 113 finished.\n",
      "🚀 Sending chunk 114/1097 (rows 30000)\n",
      "✅ Chunk 114 finished.\n",
      "🚀 Sending chunk 115/1097 (rows 30000)\n",
      "✅ Chunk 115 finished.\n",
      "🚀 Sending chunk 116/1097 (rows 30000)\n",
      "✅ Chunk 116 finished.\n",
      "🚀 Sending chunk 117/1097 (rows 30000)\n",
      "✅ Chunk 117 finished.\n",
      "🚀 Sending chunk 118/1097 (rows 30000)\n",
      "✅ Chunk 118 finished.\n",
      "🚀 Sending chunk 119/1097 (rows 30000)\n",
      "✅ Chunk 119 finished.\n",
      "🚀 Sending chunk 120/1097 (rows 30000)\n",
      "✅ Chunk 120 finished.\n",
      "🚀 Sending chunk 121/1097 (rows 30000)\n",
      "✅ Chunk 121 finished.\n",
      "🚀 Sending chunk 122/1097 (rows 30000)\n",
      "✅ Chunk 122 finished.\n",
      "🚀 Sending chunk 123/1097 (rows 30000)\n",
      "✅ Chunk 123 finished.\n",
      "🚀 Sending chunk 124/1097 (rows 30000)\n",
      "✅ Chunk 124 finished.\n",
      "🚀 Sending chunk 125/1097 (rows 30000)\n",
      "✅ Chunk 125 finished.\n",
      "🚀 Sending chunk 126/1097 (rows 30000)\n",
      "✅ Chunk 126 finished.\n",
      "🚀 Sending chunk 127/1097 (rows 30000)\n",
      "✅ Chunk 127 finished.\n",
      "🚀 Sending chunk 128/1097 (rows 30000)\n",
      "✅ Chunk 128 finished.\n",
      "🚀 Sending chunk 129/1097 (rows 30000)\n",
      "✅ Chunk 129 finished.\n",
      "🚀 Sending chunk 130/1097 (rows 30000)\n",
      "✅ Chunk 130 finished.\n",
      "🚀 Sending chunk 131/1097 (rows 30000)\n",
      "✅ Chunk 131 finished.\n",
      "🚀 Sending chunk 132/1097 (rows 30000)\n",
      "✅ Chunk 132 finished.\n",
      "🚀 Sending chunk 133/1097 (rows 30000)\n",
      "✅ Chunk 133 finished.\n",
      "🚀 Sending chunk 134/1097 (rows 30000)\n",
      "✅ Chunk 134 finished.\n",
      "🚀 Sending chunk 135/1097 (rows 30000)\n",
      "✅ Chunk 135 finished.\n",
      "🚀 Sending chunk 136/1097 (rows 30000)\n",
      "✅ Chunk 136 finished.\n",
      "🚀 Sending chunk 137/1097 (rows 30000)\n",
      "✅ Chunk 137 finished.\n",
      "🚀 Sending chunk 138/1097 (rows 30000)\n",
      "✅ Chunk 138 finished.\n",
      "🚀 Sending chunk 139/1097 (rows 30000)\n",
      "✅ Chunk 139 finished.\n",
      "🚀 Sending chunk 140/1097 (rows 30000)\n",
      "✅ Chunk 140 finished.\n",
      "🚀 Sending chunk 141/1097 (rows 30000)\n",
      "✅ Chunk 141 finished.\n",
      "🚀 Sending chunk 142/1097 (rows 30000)\n",
      "✅ Chunk 142 finished.\n",
      "🚀 Sending chunk 143/1097 (rows 30000)\n",
      "✅ Chunk 143 finished.\n",
      "🚀 Sending chunk 144/1097 (rows 30000)\n",
      "✅ Chunk 144 finished.\n",
      "🚀 Sending chunk 145/1097 (rows 30000)\n",
      "✅ Chunk 145 finished.\n",
      "🚀 Sending chunk 146/1097 (rows 30000)\n",
      "✅ Chunk 146 finished.\n",
      "🚀 Sending chunk 147/1097 (rows 30000)\n",
      "✅ Chunk 147 finished.\n",
      "🚀 Sending chunk 148/1097 (rows 30000)\n",
      "✅ Chunk 148 finished.\n",
      "🚀 Sending chunk 149/1097 (rows 30000)\n",
      "✅ Chunk 149 finished.\n",
      "🚀 Sending chunk 150/1097 (rows 30000)\n",
      "✅ Chunk 150 finished.\n",
      "🚀 Sending chunk 151/1097 (rows 30000)\n",
      "✅ Chunk 151 finished.\n",
      "🚀 Sending chunk 152/1097 (rows 30000)\n",
      "✅ Chunk 152 finished.\n",
      "🚀 Sending chunk 153/1097 (rows 30000)\n",
      "✅ Chunk 153 finished.\n",
      "🚀 Sending chunk 154/1097 (rows 30000)\n",
      "✅ Chunk 154 finished.\n",
      "🚀 Sending chunk 155/1097 (rows 30000)\n",
      "✅ Chunk 155 finished.\n",
      "🚀 Sending chunk 156/1097 (rows 30000)\n",
      "✅ Chunk 156 finished.\n",
      "🚀 Sending chunk 157/1097 (rows 30000)\n",
      "✅ Chunk 157 finished.\n",
      "🚀 Sending chunk 158/1097 (rows 30000)\n",
      "✅ Chunk 158 finished.\n",
      "🚀 Sending chunk 159/1097 (rows 30000)\n",
      "✅ Chunk 159 finished.\n",
      "🚀 Sending chunk 160/1097 (rows 30000)\n",
      "✅ Chunk 160 finished.\n",
      "🚀 Sending chunk 161/1097 (rows 30000)\n",
      "✅ Chunk 161 finished.\n",
      "🚀 Sending chunk 162/1097 (rows 30000)\n",
      "✅ Chunk 162 finished.\n",
      "🚀 Sending chunk 163/1097 (rows 30000)\n",
      "✅ Chunk 163 finished.\n",
      "🚀 Sending chunk 164/1097 (rows 30000)\n",
      "✅ Chunk 164 finished.\n",
      "🚀 Sending chunk 165/1097 (rows 30000)\n",
      "✅ Chunk 165 finished.\n",
      "🚀 Sending chunk 166/1097 (rows 30000)\n",
      "✅ Chunk 166 finished.\n",
      "🚀 Sending chunk 167/1097 (rows 30000)\n",
      "✅ Chunk 167 finished.\n",
      "🚀 Sending chunk 168/1097 (rows 30000)\n",
      "✅ Chunk 168 finished.\n",
      "🚀 Sending chunk 169/1097 (rows 30000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 30\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 Sending chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (rows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunk_rows)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     acted_in_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    CALL apoc.periodic.iterate(\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNWIND $rows AS row RETURN row\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43macted_in_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_rows\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎯 All ACTED_IN relationships created successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\database.py:405\u001b[0m, in \u001b[0;36mGraph.run\u001b[1;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, cypher, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwparameters):\n\u001b[0;32m    396\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Run a single read/write query within an auto-commit\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    :class:`~py2neo.Transaction`.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcypher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\database.py:992\u001b[0m, in \u001b[0;36mTransaction.run\u001b[1;34m(self, cypher, parameters, **kwparameters)\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    989\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector\u001b[38;5;241m.\u001b[39mauto_run(cypher, parameters,\n\u001b[0;32m    990\u001b[0m                                           graph_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    991\u001b[0m                                           readonly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadonly)\n\u001b[1;32m--> 992\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Cursor(result, hydrant)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\__init__.py:1434\u001b[0m, in \u001b[0;36mConnector.pull\u001b[1;34m(self, result, n)\u001b[0m\n\u001b[0;32m   1432\u001b[0m cx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reacquire(result\u001b[38;5;241m.\u001b[39mtransaction)\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1434\u001b[0m     \u001b[43mcx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ConnectionUnavailable, ConnectionBroken):\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprune(cx\u001b[38;5;241m.\u001b[39mprofile)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\bolt.py:995\u001b[0m, in \u001b[0;36mBolt4x0.pull\u001b[1;34m(self, result, n, capacity)\u001b[0m\n\u001b[0;32m    993\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(response, final\u001b[38;5;241m=\u001b[39m(n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 995\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BrokenWireError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    997\u001b[0m     result\u001b[38;5;241m.\u001b[39mtransaction\u001b[38;5;241m.\u001b[39mmark_broken()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\bolt.py:799\u001b[0m, in \u001b[0;36mBolt1._sync\u001b[1;34m(self, *responses)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend()\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[1;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\bolt.py:794\u001b[0m, in \u001b[0;36mBolt1._wait\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Read all incoming responses up to and including a\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;124;03mparticular response.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03mThis method calls fetch, but does not raise an exception on\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03mFAILURE.\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mfull() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\bolt.py:769\u001b[0m, in \u001b[0;36mBolt1._fetch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Fetch and process the next incoming message.\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m    This method does not raise an exception on receipt of a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03m    failed state into an exception.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 769\u001b[0m     tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0x70\u001b[39m:\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_responses\u001b[38;5;241m.\u001b[39mpopleft()\u001b[38;5;241m.\u001b[39mset_success(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfields[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\bolt.py:696\u001b[0m, in \u001b[0;36mBolt1.read_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_message\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 696\u001b[0m     tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0x71\u001b[39m:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;66;03m# If a RECORD is received, check for more records\u001b[39;00m\n\u001b[0;32m    699\u001b[0m         \u001b[38;5;66;03m# in the buffer immediately following, and log and\u001b[39;00m\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;66;03m# add them all at the same time\u001b[39;00m\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mpeek_message() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0x71\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\client\\bolt.py:156\u001b[0m, in \u001b[0;36mBoltMessageReader.read_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m         hi, lo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwire\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m WireError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    158\u001b[0m         raise_from(ConnectionBroken(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to read message\u001b[39m\u001b[38;5;124m\"\u001b[39m), error)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py2neo\\wiring.py:117\u001b[0m, in \u001b[0;36mWire.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    115\u001b[0m requested \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(required, \u001b[38;5;241m16384\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     received \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIOError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__mark_broken(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWire broken\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "chunk_size = 30000  # Number of rows to send per chunk\n",
    "total_chunks = math.ceil(len(acted_in_row) / chunk_size)\n",
    "\n",
    "print(f\"🔵 Total chunks to send: {total_chunks}\")\n",
    "\n",
    "for chunk_idx in range(total_chunks):\n",
    "    chunk_rows = acted_in_row[chunk_idx * chunk_size : (chunk_idx + 1) * chunk_size]\n",
    "    \n",
    "    print(f\"🚀 Sending chunk {chunk_idx + 1}/{total_chunks} (rows {len(chunk_rows)})\")\n",
    "\n",
    "    acted_in_query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      'UNWIND $rows AS row RETURN row',\n",
    "      '\n",
    "        WITH row\n",
    "        MATCH (a:Actor {id: row.personId})\n",
    "        MATCH (m:Movie {id: row.movieId})\n",
    "        MERGE (a)-[:ACTED_IN]->(m)\n",
    "      ',\n",
    "      {\n",
    "        batchSize:2000,\n",
    "        parallel:false,\n",
    "        params: {rows: $rows}\n",
    "      }\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    graph.run(acted_in_query, parameters={\"rows\": chunk_rows})\n",
    "\n",
    "    print(f\"✅ Chunk {chunk_idx + 1} finished.\")\n",
    "\n",
    "print(\"🎯 All ACTED_IN relationships created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506a4d5-f44f-4885-8ec5-0bc78babe5e8",
   "metadata": {},
   "source": [
    "### create DIRECTED relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "961b17fe-e458-4fa6-b7ff-e92d02ceaaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7936130, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1ea0116-9569-4829-9853-4db09f6a2cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Total chunks to send: 265\n",
      "🚀 Sending chunk 1/265 (rows 30000)\n",
      "✅ Chunk 1 finished.\n",
      "🚀 Sending chunk 2/265 (rows 30000)\n",
      "✅ Chunk 2 finished.\n",
      "🚀 Sending chunk 3/265 (rows 30000)\n",
      "✅ Chunk 3 finished.\n",
      "🚀 Sending chunk 4/265 (rows 30000)\n",
      "✅ Chunk 4 finished.\n",
      "🚀 Sending chunk 5/265 (rows 30000)\n",
      "✅ Chunk 5 finished.\n",
      "🚀 Sending chunk 6/265 (rows 30000)\n",
      "✅ Chunk 6 finished.\n",
      "🚀 Sending chunk 7/265 (rows 30000)\n",
      "✅ Chunk 7 finished.\n",
      "🚀 Sending chunk 8/265 (rows 30000)\n",
      "✅ Chunk 8 finished.\n",
      "🚀 Sending chunk 9/265 (rows 30000)\n",
      "✅ Chunk 9 finished.\n",
      "🚀 Sending chunk 10/265 (rows 30000)\n",
      "✅ Chunk 10 finished.\n",
      "🚀 Sending chunk 11/265 (rows 30000)\n",
      "✅ Chunk 11 finished.\n",
      "🚀 Sending chunk 12/265 (rows 30000)\n",
      "✅ Chunk 12 finished.\n",
      "🚀 Sending chunk 13/265 (rows 30000)\n",
      "✅ Chunk 13 finished.\n",
      "🚀 Sending chunk 14/265 (rows 30000)\n",
      "✅ Chunk 14 finished.\n",
      "🚀 Sending chunk 15/265 (rows 30000)\n",
      "✅ Chunk 15 finished.\n",
      "🚀 Sending chunk 16/265 (rows 30000)\n",
      "✅ Chunk 16 finished.\n",
      "🚀 Sending chunk 17/265 (rows 30000)\n",
      "✅ Chunk 17 finished.\n",
      "🚀 Sending chunk 18/265 (rows 30000)\n",
      "✅ Chunk 18 finished.\n",
      "🚀 Sending chunk 19/265 (rows 30000)\n",
      "✅ Chunk 19 finished.\n",
      "🚀 Sending chunk 20/265 (rows 30000)\n",
      "✅ Chunk 20 finished.\n",
      "🚀 Sending chunk 21/265 (rows 30000)\n",
      "✅ Chunk 21 finished.\n",
      "🚀 Sending chunk 22/265 (rows 30000)\n",
      "✅ Chunk 22 finished.\n",
      "🚀 Sending chunk 23/265 (rows 30000)\n",
      "✅ Chunk 23 finished.\n",
      "🚀 Sending chunk 24/265 (rows 30000)\n",
      "✅ Chunk 24 finished.\n",
      "🚀 Sending chunk 25/265 (rows 30000)\n",
      "✅ Chunk 25 finished.\n",
      "🚀 Sending chunk 26/265 (rows 30000)\n",
      "✅ Chunk 26 finished.\n",
      "🚀 Sending chunk 27/265 (rows 30000)\n",
      "✅ Chunk 27 finished.\n",
      "🚀 Sending chunk 28/265 (rows 30000)\n",
      "✅ Chunk 28 finished.\n",
      "🚀 Sending chunk 29/265 (rows 30000)\n",
      "✅ Chunk 29 finished.\n",
      "🚀 Sending chunk 30/265 (rows 30000)\n",
      "✅ Chunk 30 finished.\n",
      "🚀 Sending chunk 31/265 (rows 30000)\n",
      "✅ Chunk 31 finished.\n",
      "🚀 Sending chunk 32/265 (rows 30000)\n",
      "✅ Chunk 32 finished.\n",
      "🚀 Sending chunk 33/265 (rows 30000)\n",
      "✅ Chunk 33 finished.\n",
      "🚀 Sending chunk 34/265 (rows 30000)\n",
      "✅ Chunk 34 finished.\n",
      "🚀 Sending chunk 35/265 (rows 30000)\n",
      "✅ Chunk 35 finished.\n",
      "🚀 Sending chunk 36/265 (rows 30000)\n",
      "✅ Chunk 36 finished.\n",
      "🚀 Sending chunk 37/265 (rows 30000)\n",
      "✅ Chunk 37 finished.\n",
      "🚀 Sending chunk 38/265 (rows 30000)\n",
      "✅ Chunk 38 finished.\n",
      "🚀 Sending chunk 39/265 (rows 30000)\n",
      "✅ Chunk 39 finished.\n",
      "🚀 Sending chunk 40/265 (rows 30000)\n",
      "✅ Chunk 40 finished.\n",
      "🚀 Sending chunk 41/265 (rows 30000)\n",
      "✅ Chunk 41 finished.\n",
      "🚀 Sending chunk 42/265 (rows 30000)\n",
      "✅ Chunk 42 finished.\n",
      "🚀 Sending chunk 43/265 (rows 30000)\n",
      "✅ Chunk 43 finished.\n",
      "🚀 Sending chunk 44/265 (rows 30000)\n",
      "✅ Chunk 44 finished.\n",
      "🚀 Sending chunk 45/265 (rows 30000)\n",
      "✅ Chunk 45 finished.\n",
      "🚀 Sending chunk 46/265 (rows 30000)\n",
      "✅ Chunk 46 finished.\n",
      "🚀 Sending chunk 47/265 (rows 30000)\n",
      "✅ Chunk 47 finished.\n",
      "🚀 Sending chunk 48/265 (rows 30000)\n",
      "✅ Chunk 48 finished.\n",
      "🚀 Sending chunk 49/265 (rows 30000)\n",
      "✅ Chunk 49 finished.\n",
      "🚀 Sending chunk 50/265 (rows 30000)\n",
      "✅ Chunk 50 finished.\n",
      "🚀 Sending chunk 51/265 (rows 30000)\n",
      "✅ Chunk 51 finished.\n",
      "🚀 Sending chunk 52/265 (rows 30000)\n",
      "✅ Chunk 52 finished.\n",
      "🚀 Sending chunk 53/265 (rows 30000)\n",
      "✅ Chunk 53 finished.\n",
      "🚀 Sending chunk 54/265 (rows 30000)\n",
      "✅ Chunk 54 finished.\n",
      "🚀 Sending chunk 55/265 (rows 30000)\n",
      "✅ Chunk 55 finished.\n",
      "🚀 Sending chunk 56/265 (rows 30000)\n",
      "✅ Chunk 56 finished.\n",
      "🚀 Sending chunk 57/265 (rows 30000)\n",
      "✅ Chunk 57 finished.\n",
      "🚀 Sending chunk 58/265 (rows 30000)\n",
      "✅ Chunk 58 finished.\n",
      "🚀 Sending chunk 59/265 (rows 30000)\n",
      "✅ Chunk 59 finished.\n",
      "🚀 Sending chunk 60/265 (rows 30000)\n",
      "✅ Chunk 60 finished.\n",
      "🚀 Sending chunk 61/265 (rows 30000)\n",
      "✅ Chunk 61 finished.\n",
      "🚀 Sending chunk 62/265 (rows 30000)\n",
      "✅ Chunk 62 finished.\n",
      "🚀 Sending chunk 63/265 (rows 30000)\n",
      "✅ Chunk 63 finished.\n",
      "🚀 Sending chunk 64/265 (rows 30000)\n",
      "✅ Chunk 64 finished.\n",
      "🚀 Sending chunk 65/265 (rows 30000)\n",
      "✅ Chunk 65 finished.\n",
      "🚀 Sending chunk 66/265 (rows 30000)\n",
      "✅ Chunk 66 finished.\n",
      "🚀 Sending chunk 67/265 (rows 30000)\n",
      "✅ Chunk 67 finished.\n",
      "🚀 Sending chunk 68/265 (rows 30000)\n",
      "✅ Chunk 68 finished.\n",
      "🚀 Sending chunk 69/265 (rows 30000)\n",
      "✅ Chunk 69 finished.\n",
      "🚀 Sending chunk 70/265 (rows 30000)\n",
      "✅ Chunk 70 finished.\n",
      "🚀 Sending chunk 71/265 (rows 30000)\n",
      "✅ Chunk 71 finished.\n",
      "🚀 Sending chunk 72/265 (rows 30000)\n",
      "✅ Chunk 72 finished.\n",
      "🚀 Sending chunk 73/265 (rows 30000)\n",
      "✅ Chunk 73 finished.\n",
      "🚀 Sending chunk 74/265 (rows 30000)\n",
      "✅ Chunk 74 finished.\n",
      "🚀 Sending chunk 75/265 (rows 30000)\n",
      "✅ Chunk 75 finished.\n",
      "🚀 Sending chunk 76/265 (rows 30000)\n",
      "✅ Chunk 76 finished.\n",
      "🚀 Sending chunk 77/265 (rows 30000)\n",
      "✅ Chunk 77 finished.\n",
      "🚀 Sending chunk 78/265 (rows 30000)\n",
      "✅ Chunk 78 finished.\n",
      "🚀 Sending chunk 79/265 (rows 30000)\n",
      "✅ Chunk 79 finished.\n",
      "🚀 Sending chunk 80/265 (rows 30000)\n",
      "✅ Chunk 80 finished.\n",
      "🚀 Sending chunk 81/265 (rows 30000)\n",
      "✅ Chunk 81 finished.\n",
      "🚀 Sending chunk 82/265 (rows 30000)\n",
      "✅ Chunk 82 finished.\n",
      "🚀 Sending chunk 83/265 (rows 30000)\n",
      "✅ Chunk 83 finished.\n",
      "🚀 Sending chunk 84/265 (rows 30000)\n",
      "✅ Chunk 84 finished.\n",
      "🚀 Sending chunk 85/265 (rows 30000)\n",
      "✅ Chunk 85 finished.\n",
      "🚀 Sending chunk 86/265 (rows 30000)\n",
      "✅ Chunk 86 finished.\n",
      "🚀 Sending chunk 87/265 (rows 30000)\n",
      "✅ Chunk 87 finished.\n",
      "🚀 Sending chunk 88/265 (rows 30000)\n",
      "✅ Chunk 88 finished.\n",
      "🚀 Sending chunk 89/265 (rows 30000)\n",
      "✅ Chunk 89 finished.\n",
      "🚀 Sending chunk 90/265 (rows 30000)\n",
      "✅ Chunk 90 finished.\n",
      "🚀 Sending chunk 91/265 (rows 30000)\n",
      "✅ Chunk 91 finished.\n",
      "🚀 Sending chunk 92/265 (rows 30000)\n",
      "✅ Chunk 92 finished.\n",
      "🚀 Sending chunk 93/265 (rows 30000)\n",
      "✅ Chunk 93 finished.\n",
      "🚀 Sending chunk 94/265 (rows 30000)\n",
      "✅ Chunk 94 finished.\n",
      "🚀 Sending chunk 95/265 (rows 30000)\n",
      "✅ Chunk 95 finished.\n",
      "🚀 Sending chunk 96/265 (rows 30000)\n",
      "✅ Chunk 96 finished.\n",
      "🚀 Sending chunk 97/265 (rows 30000)\n",
      "✅ Chunk 97 finished.\n",
      "🚀 Sending chunk 98/265 (rows 30000)\n",
      "✅ Chunk 98 finished.\n",
      "🚀 Sending chunk 99/265 (rows 30000)\n",
      "✅ Chunk 99 finished.\n",
      "🚀 Sending chunk 100/265 (rows 30000)\n",
      "✅ Chunk 100 finished.\n",
      "🚀 Sending chunk 101/265 (rows 30000)\n",
      "✅ Chunk 101 finished.\n",
      "🚀 Sending chunk 102/265 (rows 30000)\n",
      "✅ Chunk 102 finished.\n",
      "🚀 Sending chunk 103/265 (rows 30000)\n",
      "✅ Chunk 103 finished.\n",
      "🚀 Sending chunk 104/265 (rows 30000)\n",
      "✅ Chunk 104 finished.\n",
      "🚀 Sending chunk 105/265 (rows 30000)\n",
      "✅ Chunk 105 finished.\n",
      "🚀 Sending chunk 106/265 (rows 30000)\n",
      "✅ Chunk 106 finished.\n",
      "🚀 Sending chunk 107/265 (rows 30000)\n",
      "✅ Chunk 107 finished.\n",
      "🚀 Sending chunk 108/265 (rows 30000)\n",
      "✅ Chunk 108 finished.\n",
      "🚀 Sending chunk 109/265 (rows 30000)\n",
      "✅ Chunk 109 finished.\n",
      "🚀 Sending chunk 110/265 (rows 30000)\n",
      "✅ Chunk 110 finished.\n",
      "🚀 Sending chunk 111/265 (rows 30000)\n",
      "✅ Chunk 111 finished.\n",
      "🚀 Sending chunk 112/265 (rows 30000)\n",
      "✅ Chunk 112 finished.\n",
      "🚀 Sending chunk 113/265 (rows 30000)\n",
      "✅ Chunk 113 finished.\n",
      "🚀 Sending chunk 114/265 (rows 30000)\n",
      "✅ Chunk 114 finished.\n",
      "🚀 Sending chunk 115/265 (rows 30000)\n",
      "✅ Chunk 115 finished.\n",
      "🚀 Sending chunk 116/265 (rows 30000)\n",
      "✅ Chunk 116 finished.\n",
      "🚀 Sending chunk 117/265 (rows 30000)\n",
      "✅ Chunk 117 finished.\n",
      "🚀 Sending chunk 118/265 (rows 30000)\n",
      "✅ Chunk 118 finished.\n",
      "🚀 Sending chunk 119/265 (rows 30000)\n",
      "✅ Chunk 119 finished.\n",
      "🚀 Sending chunk 120/265 (rows 30000)\n",
      "✅ Chunk 120 finished.\n",
      "🚀 Sending chunk 121/265 (rows 30000)\n",
      "✅ Chunk 121 finished.\n",
      "🚀 Sending chunk 122/265 (rows 30000)\n",
      "✅ Chunk 122 finished.\n",
      "🚀 Sending chunk 123/265 (rows 30000)\n",
      "✅ Chunk 123 finished.\n",
      "🚀 Sending chunk 124/265 (rows 30000)\n",
      "✅ Chunk 124 finished.\n",
      "🚀 Sending chunk 125/265 (rows 30000)\n",
      "✅ Chunk 125 finished.\n",
      "🚀 Sending chunk 126/265 (rows 30000)\n",
      "✅ Chunk 126 finished.\n",
      "🚀 Sending chunk 127/265 (rows 30000)\n",
      "✅ Chunk 127 finished.\n",
      "🚀 Sending chunk 128/265 (rows 30000)\n",
      "✅ Chunk 128 finished.\n",
      "🚀 Sending chunk 129/265 (rows 30000)\n",
      "✅ Chunk 129 finished.\n",
      "🚀 Sending chunk 130/265 (rows 30000)\n",
      "✅ Chunk 130 finished.\n",
      "🚀 Sending chunk 131/265 (rows 30000)\n",
      "✅ Chunk 131 finished.\n",
      "🚀 Sending chunk 132/265 (rows 30000)\n",
      "✅ Chunk 132 finished.\n",
      "🚀 Sending chunk 133/265 (rows 30000)\n",
      "✅ Chunk 133 finished.\n",
      "🚀 Sending chunk 134/265 (rows 30000)\n",
      "✅ Chunk 134 finished.\n",
      "🚀 Sending chunk 135/265 (rows 30000)\n",
      "✅ Chunk 135 finished.\n",
      "🚀 Sending chunk 136/265 (rows 30000)\n",
      "✅ Chunk 136 finished.\n",
      "🚀 Sending chunk 137/265 (rows 30000)\n",
      "✅ Chunk 137 finished.\n",
      "🚀 Sending chunk 138/265 (rows 30000)\n",
      "✅ Chunk 138 finished.\n",
      "🚀 Sending chunk 139/265 (rows 30000)\n",
      "✅ Chunk 139 finished.\n",
      "🚀 Sending chunk 140/265 (rows 30000)\n",
      "✅ Chunk 140 finished.\n",
      "🚀 Sending chunk 141/265 (rows 30000)\n",
      "✅ Chunk 141 finished.\n",
      "🚀 Sending chunk 142/265 (rows 30000)\n",
      "✅ Chunk 142 finished.\n",
      "🚀 Sending chunk 143/265 (rows 30000)\n",
      "✅ Chunk 143 finished.\n",
      "🚀 Sending chunk 144/265 (rows 30000)\n",
      "✅ Chunk 144 finished.\n",
      "🚀 Sending chunk 145/265 (rows 30000)\n",
      "✅ Chunk 145 finished.\n",
      "🚀 Sending chunk 146/265 (rows 30000)\n",
      "✅ Chunk 146 finished.\n",
      "🚀 Sending chunk 147/265 (rows 30000)\n",
      "✅ Chunk 147 finished.\n",
      "🚀 Sending chunk 148/265 (rows 30000)\n",
      "✅ Chunk 148 finished.\n",
      "🚀 Sending chunk 149/265 (rows 30000)\n",
      "✅ Chunk 149 finished.\n",
      "🚀 Sending chunk 150/265 (rows 30000)\n",
      "✅ Chunk 150 finished.\n",
      "🚀 Sending chunk 151/265 (rows 30000)\n",
      "✅ Chunk 151 finished.\n",
      "🚀 Sending chunk 152/265 (rows 30000)\n",
      "✅ Chunk 152 finished.\n",
      "🚀 Sending chunk 153/265 (rows 30000)\n",
      "✅ Chunk 153 finished.\n",
      "🚀 Sending chunk 154/265 (rows 30000)\n",
      "✅ Chunk 154 finished.\n",
      "🚀 Sending chunk 155/265 (rows 30000)\n",
      "✅ Chunk 155 finished.\n",
      "🚀 Sending chunk 156/265 (rows 30000)\n",
      "✅ Chunk 156 finished.\n",
      "🚀 Sending chunk 157/265 (rows 30000)\n",
      "✅ Chunk 157 finished.\n",
      "🚀 Sending chunk 158/265 (rows 30000)\n",
      "✅ Chunk 158 finished.\n",
      "🚀 Sending chunk 159/265 (rows 30000)\n",
      "✅ Chunk 159 finished.\n",
      "🚀 Sending chunk 160/265 (rows 30000)\n",
      "✅ Chunk 160 finished.\n",
      "🚀 Sending chunk 161/265 (rows 30000)\n",
      "✅ Chunk 161 finished.\n",
      "🚀 Sending chunk 162/265 (rows 30000)\n",
      "✅ Chunk 162 finished.\n",
      "🚀 Sending chunk 163/265 (rows 30000)\n",
      "✅ Chunk 163 finished.\n",
      "🚀 Sending chunk 164/265 (rows 30000)\n",
      "✅ Chunk 164 finished.\n",
      "🚀 Sending chunk 165/265 (rows 30000)\n",
      "✅ Chunk 165 finished.\n",
      "🚀 Sending chunk 166/265 (rows 30000)\n",
      "✅ Chunk 166 finished.\n",
      "🚀 Sending chunk 167/265 (rows 30000)\n",
      "✅ Chunk 167 finished.\n",
      "🚀 Sending chunk 168/265 (rows 30000)\n",
      "✅ Chunk 168 finished.\n",
      "🚀 Sending chunk 169/265 (rows 30000)\n",
      "✅ Chunk 169 finished.\n",
      "🚀 Sending chunk 170/265 (rows 30000)\n",
      "✅ Chunk 170 finished.\n",
      "🚀 Sending chunk 171/265 (rows 30000)\n",
      "✅ Chunk 171 finished.\n",
      "🚀 Sending chunk 172/265 (rows 30000)\n",
      "✅ Chunk 172 finished.\n",
      "🚀 Sending chunk 173/265 (rows 30000)\n",
      "✅ Chunk 173 finished.\n",
      "🚀 Sending chunk 174/265 (rows 30000)\n",
      "✅ Chunk 174 finished.\n",
      "🚀 Sending chunk 175/265 (rows 30000)\n",
      "✅ Chunk 175 finished.\n",
      "🚀 Sending chunk 176/265 (rows 30000)\n",
      "✅ Chunk 176 finished.\n",
      "🚀 Sending chunk 177/265 (rows 30000)\n",
      "✅ Chunk 177 finished.\n",
      "🚀 Sending chunk 178/265 (rows 30000)\n",
      "✅ Chunk 178 finished.\n",
      "🚀 Sending chunk 179/265 (rows 30000)\n",
      "✅ Chunk 179 finished.\n",
      "🚀 Sending chunk 180/265 (rows 30000)\n",
      "✅ Chunk 180 finished.\n",
      "🚀 Sending chunk 181/265 (rows 30000)\n",
      "✅ Chunk 181 finished.\n",
      "🚀 Sending chunk 182/265 (rows 30000)\n",
      "✅ Chunk 182 finished.\n",
      "🚀 Sending chunk 183/265 (rows 30000)\n",
      "✅ Chunk 183 finished.\n",
      "🚀 Sending chunk 184/265 (rows 30000)\n",
      "✅ Chunk 184 finished.\n",
      "🚀 Sending chunk 185/265 (rows 30000)\n",
      "✅ Chunk 185 finished.\n",
      "🚀 Sending chunk 186/265 (rows 30000)\n",
      "✅ Chunk 186 finished.\n",
      "🚀 Sending chunk 187/265 (rows 30000)\n",
      "✅ Chunk 187 finished.\n",
      "🚀 Sending chunk 188/265 (rows 30000)\n",
      "✅ Chunk 188 finished.\n",
      "🚀 Sending chunk 189/265 (rows 30000)\n",
      "✅ Chunk 189 finished.\n",
      "🚀 Sending chunk 190/265 (rows 30000)\n",
      "✅ Chunk 190 finished.\n",
      "🚀 Sending chunk 191/265 (rows 30000)\n",
      "✅ Chunk 191 finished.\n",
      "🚀 Sending chunk 192/265 (rows 30000)\n",
      "✅ Chunk 192 finished.\n",
      "🚀 Sending chunk 193/265 (rows 30000)\n",
      "✅ Chunk 193 finished.\n",
      "🚀 Sending chunk 194/265 (rows 30000)\n",
      "✅ Chunk 194 finished.\n",
      "🚀 Sending chunk 195/265 (rows 30000)\n",
      "✅ Chunk 195 finished.\n",
      "🚀 Sending chunk 196/265 (rows 30000)\n",
      "✅ Chunk 196 finished.\n",
      "🚀 Sending chunk 197/265 (rows 30000)\n",
      "✅ Chunk 197 finished.\n",
      "🚀 Sending chunk 198/265 (rows 30000)\n",
      "✅ Chunk 198 finished.\n",
      "🚀 Sending chunk 199/265 (rows 30000)\n",
      "✅ Chunk 199 finished.\n",
      "🚀 Sending chunk 200/265 (rows 30000)\n",
      "✅ Chunk 200 finished.\n",
      "🚀 Sending chunk 201/265 (rows 30000)\n",
      "✅ Chunk 201 finished.\n",
      "🚀 Sending chunk 202/265 (rows 30000)\n",
      "✅ Chunk 202 finished.\n",
      "🚀 Sending chunk 203/265 (rows 30000)\n",
      "✅ Chunk 203 finished.\n",
      "🚀 Sending chunk 204/265 (rows 30000)\n",
      "✅ Chunk 204 finished.\n",
      "🚀 Sending chunk 205/265 (rows 30000)\n",
      "✅ Chunk 205 finished.\n",
      "🚀 Sending chunk 206/265 (rows 30000)\n",
      "✅ Chunk 206 finished.\n",
      "🚀 Sending chunk 207/265 (rows 30000)\n",
      "✅ Chunk 207 finished.\n",
      "🚀 Sending chunk 208/265 (rows 30000)\n",
      "✅ Chunk 208 finished.\n",
      "🚀 Sending chunk 209/265 (rows 30000)\n",
      "✅ Chunk 209 finished.\n",
      "🚀 Sending chunk 210/265 (rows 30000)\n",
      "✅ Chunk 210 finished.\n",
      "🚀 Sending chunk 211/265 (rows 30000)\n",
      "✅ Chunk 211 finished.\n",
      "🚀 Sending chunk 212/265 (rows 30000)\n",
      "✅ Chunk 212 finished.\n",
      "🚀 Sending chunk 213/265 (rows 30000)\n",
      "✅ Chunk 213 finished.\n",
      "🚀 Sending chunk 214/265 (rows 30000)\n",
      "✅ Chunk 214 finished.\n",
      "🚀 Sending chunk 215/265 (rows 30000)\n",
      "✅ Chunk 215 finished.\n",
      "🚀 Sending chunk 216/265 (rows 30000)\n",
      "✅ Chunk 216 finished.\n",
      "🚀 Sending chunk 217/265 (rows 30000)\n",
      "✅ Chunk 217 finished.\n",
      "🚀 Sending chunk 218/265 (rows 30000)\n",
      "✅ Chunk 218 finished.\n",
      "🚀 Sending chunk 219/265 (rows 30000)\n",
      "✅ Chunk 219 finished.\n",
      "🚀 Sending chunk 220/265 (rows 30000)\n",
      "✅ Chunk 220 finished.\n",
      "🚀 Sending chunk 221/265 (rows 30000)\n",
      "✅ Chunk 221 finished.\n",
      "🚀 Sending chunk 222/265 (rows 30000)\n",
      "✅ Chunk 222 finished.\n",
      "🚀 Sending chunk 223/265 (rows 30000)\n",
      "✅ Chunk 223 finished.\n",
      "🚀 Sending chunk 224/265 (rows 30000)\n",
      "✅ Chunk 224 finished.\n",
      "🚀 Sending chunk 225/265 (rows 30000)\n",
      "✅ Chunk 225 finished.\n",
      "🚀 Sending chunk 226/265 (rows 30000)\n",
      "✅ Chunk 226 finished.\n",
      "🚀 Sending chunk 227/265 (rows 30000)\n",
      "✅ Chunk 227 finished.\n",
      "🚀 Sending chunk 228/265 (rows 30000)\n",
      "✅ Chunk 228 finished.\n",
      "🚀 Sending chunk 229/265 (rows 30000)\n",
      "✅ Chunk 229 finished.\n",
      "🚀 Sending chunk 230/265 (rows 30000)\n",
      "✅ Chunk 230 finished.\n",
      "🚀 Sending chunk 231/265 (rows 30000)\n",
      "✅ Chunk 231 finished.\n",
      "🚀 Sending chunk 232/265 (rows 30000)\n",
      "✅ Chunk 232 finished.\n",
      "🚀 Sending chunk 233/265 (rows 30000)\n",
      "✅ Chunk 233 finished.\n",
      "🚀 Sending chunk 234/265 (rows 30000)\n",
      "✅ Chunk 234 finished.\n",
      "🚀 Sending chunk 235/265 (rows 30000)\n",
      "✅ Chunk 235 finished.\n",
      "🚀 Sending chunk 236/265 (rows 30000)\n",
      "✅ Chunk 236 finished.\n",
      "🚀 Sending chunk 237/265 (rows 30000)\n",
      "✅ Chunk 237 finished.\n",
      "🚀 Sending chunk 238/265 (rows 30000)\n",
      "✅ Chunk 238 finished.\n",
      "🚀 Sending chunk 239/265 (rows 30000)\n",
      "✅ Chunk 239 finished.\n",
      "🚀 Sending chunk 240/265 (rows 30000)\n",
      "✅ Chunk 240 finished.\n",
      "🚀 Sending chunk 241/265 (rows 30000)\n",
      "✅ Chunk 241 finished.\n",
      "🚀 Sending chunk 242/265 (rows 30000)\n",
      "✅ Chunk 242 finished.\n",
      "🚀 Sending chunk 243/265 (rows 30000)\n",
      "✅ Chunk 243 finished.\n",
      "🚀 Sending chunk 244/265 (rows 30000)\n",
      "✅ Chunk 244 finished.\n",
      "🚀 Sending chunk 245/265 (rows 30000)\n",
      "✅ Chunk 245 finished.\n",
      "🚀 Sending chunk 246/265 (rows 30000)\n",
      "✅ Chunk 246 finished.\n",
      "🚀 Sending chunk 247/265 (rows 30000)\n",
      "✅ Chunk 247 finished.\n",
      "🚀 Sending chunk 248/265 (rows 30000)\n",
      "✅ Chunk 248 finished.\n",
      "🚀 Sending chunk 249/265 (rows 30000)\n",
      "✅ Chunk 249 finished.\n",
      "🚀 Sending chunk 250/265 (rows 30000)\n",
      "✅ Chunk 250 finished.\n",
      "🚀 Sending chunk 251/265 (rows 30000)\n",
      "✅ Chunk 251 finished.\n",
      "🚀 Sending chunk 252/265 (rows 30000)\n",
      "✅ Chunk 252 finished.\n",
      "🚀 Sending chunk 253/265 (rows 30000)\n",
      "✅ Chunk 253 finished.\n",
      "🚀 Sending chunk 254/265 (rows 30000)\n",
      "✅ Chunk 254 finished.\n",
      "🚀 Sending chunk 255/265 (rows 30000)\n",
      "✅ Chunk 255 finished.\n",
      "🚀 Sending chunk 256/265 (rows 30000)\n",
      "✅ Chunk 256 finished.\n",
      "🚀 Sending chunk 257/265 (rows 30000)\n",
      "✅ Chunk 257 finished.\n",
      "🚀 Sending chunk 258/265 (rows 30000)\n",
      "✅ Chunk 258 finished.\n",
      "🚀 Sending chunk 259/265 (rows 30000)\n",
      "✅ Chunk 259 finished.\n",
      "🚀 Sending chunk 260/265 (rows 30000)\n",
      "✅ Chunk 260 finished.\n",
      "🚀 Sending chunk 261/265 (rows 30000)\n",
      "✅ Chunk 261 finished.\n",
      "🚀 Sending chunk 262/265 (rows 30000)\n",
      "✅ Chunk 262 finished.\n",
      "🚀 Sending chunk 263/265 (rows 30000)\n",
      "✅ Chunk 263 finished.\n",
      "🚀 Sending chunk 264/265 (rows 30000)\n",
      "✅ Chunk 264 finished.\n",
      "🚀 Sending chunk 265/265 (rows 16130)\n",
      "✅ Chunk 265 finished.\n",
      "🎯 All DIRECTED relationships created successfully!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "chunk_size = 30000  # Number of rows to send per chunk\n",
    "total_chunks = math.ceil(len(directors_df) / chunk_size)\n",
    "\n",
    "print(f\"🔵 Total chunks to send: {total_chunks}\")\n",
    "\n",
    "for chunk_idx in range(total_chunks):\n",
    "    chunk_rows = directors_df[chunk_idx * chunk_size : (chunk_idx + 1) * chunk_size]\n",
    "    \n",
    "    print(f\"🚀 Sending chunk {chunk_idx + 1}/{total_chunks} (rows {len(chunk_rows)})\")\n",
    "\n",
    "    directed_query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      'UNWIND $rows AS row RETURN row',\n",
    "      '\n",
    "        WITH row\n",
    "        MATCH (d:Director {id: row.personId})\n",
    "        MATCH (m:Movie {id: row.movieId})\n",
    "        MERGE (d)-[:DIRECTED]->(m)\n",
    "      ',\n",
    "      {\n",
    "        batchSize:2000,\n",
    "        parallel:false,\n",
    "        params: {rows: $rows}\n",
    "      }\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    graph.run(directed_query, parameters={\"rows\": chunk_rows.to_dict('records')})\n",
    "\n",
    "    print(f\"✅ Chunk {chunk_idx + 1} finished.\")\n",
    "\n",
    "print(\"🎯 All DIRECTED relationships created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9b204-9762-4ddd-8250-55da27445c74",
   "metadata": {},
   "source": [
    "### finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bf117-c7cf-414e-9146-9f347f1a531e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aeae3c-3f43-4ce8-8504-c7dcfc0b43bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
